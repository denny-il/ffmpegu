---
All rights: (FFmpeg Project)[https://ffmpeg.org/legal.html]
Title: Filters
Source: https://ffmpeg.org/ffmpeg-filters.html
---

# FFmpeg Filters Documentation

This document describes filters, sources, and sinks provided by the libavfilter library.

## Table of Contents
1. [Description](#description)
2. [Filtering Introduction](#filtering-introduction)
3. [graph2dot](#graph2dot)
4. [Filtergraph description](#filtergraph-description)
5. [Timeline editing](#timeline-editing)
6. [Changing options at runtime with a command](#changing-options-at-runtime-with-a-command)
7. [Options for filters with several inputs (framesync)](#options-for-filters-with-several-inputs-framesync)
8. [Audio Filters](#audio-filters)
9. [Audio Sources](#audio-sources)
10. [Audio Sinks](#audio-sinks)
11. [Video Filters](#video-filters)
12. [CUDA Video Filters](#cuda-video-filters)
13. [OpenCL Video Filters](#opencl-video-filters)
14. [VAAPI Video Filters](#vaapi-video-filters)
15. [VideoToolbox Video Filters](#videotoolbox-video-filters)
16. [Vulkan Video Filters](#vulkan-video-filters)
17. [QSV Video Filters](#qsv-video-filters)
18. [Video Sources](#video-sources)
19. [Video Sinks](#video-sinks)
20. [Multimedia Filters](#multimedia-filters)
21. [Multimedia Sources](#multimedia-sources)

---

<span id="Description"></span>
## 1 Description

This document describes filters, sources, and sinks provided by the libavfilter library.

<span id="Filtering-Introduction"></span>
## 2 Filtering Introduction

Filtering in FFmpeg is enabled through the libavfilter library. In libavfilter, a filter can have multiple inputs and multiple outputs. To illustrate the sorts of things that are possible, we consider the following filtergraph.

```
                [main]
input --> split ---------------------> overlay --> output
            |                             ^
            |[tmp]                  [flip]|
            +-----> crop --> vflip -------+
```

This filtergraph splits the input stream in two streams, then sends one stream through the crop filter and the vflip filter, before merging it back with the other stream by overlaying it on top. You can use the following command to achieve this:

```bash
ffmpeg -i INPUT -vf "split [main][tmp]; [tmp] crop=iw:ih/2:0:0, vflip [flip]; [main][flip] overlay=0:H/2" OUTPUT
```

The result will be that the top half of the video is mirrored onto the bottom half of the output video.

Filters in the same linear chain are separated by commas, and distinct linear chains of filters are separated by semicolons. In our example, `crop,vflip` are in one linear chain, `split` and `overlay` are separately in another. The points where the linear chains join are labelled by names enclosed in square brackets. In the example, the split filter generates two outputs that are associated to the labels `[main]` and `[tmp]`.

The stream sent to the second output of `split`, labelled as `[tmp]`, is processed through the `crop` filter, which crops away the lower half part of the video, and then vertically flipped. The `overlay` filter takes in input the first unchanged output of the split filter (which was labelled as `[main]`), and overlay on its lower half the output generated by the `crop,vflip` filterchain.

Some filters take in input a list of parameters: they are specified after the filter name and an equal sign, and are separated from each other by a colon.

There exist so-called source filters that do not have an audio/video input, and sink filters that will not have audio/video output.

<span id="graph2dot"></span>
## 3 graph2dot

The `graph2dot` program included in the FFmpeg `tools` directory can be used to parse a filtergraph description and issue a corresponding textual representation in the dot language.

Invoke the command:
```bash
graph2dot -h
```
to see how to use `graph2dot`.

You can then pass the dot description to the `dot` program (from the graphviz suite of programs) and obtain a graphical representation of the filtergraph.

For example the sequence of commands:
```bash
echo GRAPH_DESCRIPTION | \
tools/graph2dot -o graph.tmp && \
dot -Tpng graph.tmp -o graph.png && \
display graph.png
```
can be used to create and display an image representing the graph described by the `GRAPH_DESCRIPTION` string. Note that this string must be a complete self-contained graph, with its inputs and outputs explicitly defined. For example if your command line is of the form:
```bash
ffmpeg -i infile -vf scale=640:360 outfile
```
your `GRAPH_DESCRIPTION` string will need to be of the form:
```bash
nullsrc,scale=640:360,nullsink
```
you may also need to set the `nullsrc` parameters and add a `format` filter in order to simulate a specific input file.

<span id="Filtergraph-description"></span>
## 4 Filtergraph description

A filtergraph is a directed graph of connected filters. It can contain cycles, and there can be multiple links between a pair of filters. Each link has one input pad on one side connecting it to one filter from which it takes its input, and one output pad on the other side connecting it to one filter accepting its output.

Each filter in a filtergraph is an instance of a filter class registered in the application, which defines the features and the number of input and output pads of the filter.

A filter with no input pads is called a "source", and a filter with no output pads is called a "sink".

### 4.1 Filtergraph syntax

A filtergraph has a textual representation, which is recognized by the `-filter`/`-vf`/`-af` and `-filter_complex` options in `ffmpeg` and `-vf`/`-af` in `ffplay`, and by the `avfilter_graph_parse_ptr()` function defined in `libavfilter/avfilter.h`.

A filterchain consists of a sequence of connected filters, each one connected to the previous one in the sequence. A filterchain is represented by a list of ","-separated filter descriptions.

A filtergraph consists of a sequence of filterchains. A sequence of filterchains is represented by a list of ";"-separated filterchain descriptions.

A filter is represented by a string of the form:
`[in_link_1]...[in_link_N]filter_name@id=arguments[out_link_1]...[out_link_M]`

`filter_name` is the name of the filter class of which the described filter is an instance of, and has to be the name of one of the filter classes registered in the program optionally followed by "@id". The name of the filter class is optionally followed by a string "=arguments".

`arguments` is a string which contains the parameters used to initialize the filter instance. It may have one of two forms:
*   A ':'-separated list of `key=value` pairs.
*   A ':'-separated list of `value`. In this case, the keys are assumed to be the option names in the order they are declared. E.g. the `fade` filter declares three options in this order â€“ `type`, `start_frame` and `nb_frames`. Then the parameter list `in:0:30` means that the value `in` is assigned to the option `type`, `0` to `start_frame` and `30` to `nb_frames`.
*   A ':'-separated list of mixed direct `value` and long `key=value` pairs. The direct `value` must precede the `key=value` pairs, and follow the same constraints order of the previous point. The following `key=value` pairs can be set in any preferred order.

If the option value itself is a list of items (e.g. the `format` filter takes a list of pixel formats), the items in the list are usually separated by '|'.

The list of arguments can be quoted using the character "'" as initial and ending mark, and the character "\\" for escaping the characters within the quoted text; otherwise the argument string is considered terminated when the next special character (belonging to the set "[]=;,") is encountered.

A special syntax implemented in the `ffmpeg` CLI tool allows loading option values from files. This is done be prepending a slash '/' to the option name, then the supplied value is interpreted as a path from which the actual value is loaded. E.g.
```bash
ffmpeg -i <INPUT> -vf drawtext=/text=/tmp/some_text <OUTPUT>
```
will load the text to be drawn from `/tmp/some_text`. API users wishing to implement a similar feature should use the `avfilter_graph_segment_*()` functions together with custom IO code.

The name and arguments of the filter are optionally preceded and followed by a list of link labels. A link label allows one to name a link and associate it to a filter output or input pad. The preceding labels `in_link_1` ... `in_link_N`, are associated to the filter input pads, the following labels `out_link_1` ... `out_link_M`, are associated to the output pads.

When two link labels with the same name are found in the filtergraph, a link between the corresponding input and output pad is created.

If an output pad is not labelled, it is linked by default to the first unlabelled input pad of the next filter in the filterchain. For example in the filterchain:
```
nullsrc, split[L1], [L2]overlay, nullsink
```
the split filter instance has two output pads, and the overlay filter instance two input pads. The first output pad of split is labelled "L1", the first input pad of overlay is labelled "L2", and the second output pad of split is linked to the second input pad of overlay, which are both unlabelled.

In a filter description, if the input label of the first filter is not specified, "in" is assumed; if the output label of the last filter is not specified, "out" is assumed.

In a complete filterchain all the unlabelled filter input and output pads must be connected. A filtergraph is considered valid if all the filter input and output pads of all the filterchains are connected.

Leading and trailing whitespaces (space, tabs, or line feeds) separating tokens in the filtergraph specification are ignored. This means that the filtergraph can be expressed using empty lines and spaces to improve readability.

For example, the filtergraph:
```
testsrc,split[L1],hflip[L2];[L1][L2] hstack
```
can be represented as:
```
testsrc,
split [L1], hflip [L2];

[L1][L2] hstack
```

Libavfilter will automatically insert `scale` filters where format conversion is required. It is possible to specify swscale flags for those automatically inserted scalers by prepending `sws_flags=flags;` to the filtergraph description.

### 4.2 Notes on filtergraph escaping

Filtergraph description composition entails several levels of escaping.

A first level escaping affects the content of each filter option value, which may contain the special character `:` used to separate values, or one of the escaping characters `\'`.

A second level escaping affects the whole filter description, which may contain the escaping characters `\'` or the special characters `[],;` used by the filtergraph description.

Finally, when you specify a filtergraph on a shell commandline, you need to perform a third level escaping for the shell special characters contained within it.

For example, consider the following string to be embedded in the `drawtext` filter description `text` value:
`this is a 'string': may contain one, or more, special characters`

This string contains the `'` special escaping character, and the `:` special character, so it needs to be escaped in this way:
`text=this is a \'string\': may contain one, or more, special characters`

A second level of escaping is required when embedding the filter description in a filtergraph description, in order to escape all the filtergraph special characters. Thus the example above becomes:
`drawtext=text=this is a \\\'string\\\'\\: may contain one\, or more\, special characters`
(note that in addition to the `\'` escaping special characters, also `,` needs to be escaped).

Finally an additional level of escaping is needed when writing the filtergraph description in a shell command, which depends on the escaping rules of the adopted shell. For example, assuming that `\` is special and needs to be escaped with another `\`, the previous string will finally result in:
`-vf "drawtext=text=this is a \\\\\\'string\\\\\\'\\\\: may contain one\\, or more\\, special characters"`

In order to avoid cumbersome escaping when using a commandline tool accepting a filter specification as input, it is advisable to avoid direct inclusion of the filter or options specification in the shell.

For example, in case of the `drawtext` filter, you might prefer to use the `textfile` option in place of `text` to specify the text to render.

<span id="Timeline-editing"></span>
## 5 Timeline editing

Some filters support a generic `enable` option. For the filters supporting timeline editing, this option can be set to an expression which is evaluated before sending a frame to the filter. If the evaluation is non-zero, the filter will be enabled, otherwise the frame will be sent unchanged to the next filter in the filtergraph.

The expression accepts the following values:
*   **t**: timestamp expressed in seconds, NAN if the input timestamp is unknown
*   **n**: sequential number of the input frame, starting from 0
*   **pos**: the position in the file of the input frame, NAN if unknown; deprecated, do not use
*   **w**, **h**: width and height of the input frame if video

Additionally, these filters support an `enable` command that can be used to re-define the expression.

For example, to enable a blur filter (`smartblur`) from 10 seconds to 3 minutes, and a `curves` filter starting at 3 seconds:
```
smartblur = enable='between(t,10,3*60)',
curves    = enable='gte(t,3)' : preset=cross_process
```

See `ffmpeg -filters` to view which filters have timeline support.

<span id="Changing-options-at-runtime-with-a-command"></span>
## 6 Changing options at runtime with a command

Some options can be changed during the operation of the filter using a command. These options are marked 'T' on the output of `ffmpeg -h filter=<name of filter>`. The name of the command is the name of the option and the argument is the new value.

<span id="Options-for-filters-with-several-inputs-_0028framesync_0029"></span>
## 7 Options for filters with several inputs (framesync)

Some filters with several inputs support a common set of options. These options can only be set by name, not with the short notation.

*   **eof_action**: The action to take when EOF is encountered on the secondary input:
    *   `repeat`: Repeat the last frame (the default).
    *   `endall`: End both streams.
    *   `pass`: Pass the main input through.
*   **shortest**: If set to 1, force the output to terminate when the shortest input terminates. Default is 0.
*   **repeatlast**: If set to 1, force the filter to extend the last frame of secondary streams until the end of the primary stream. A value of 0 disables this behavior. Default is 1.
*   **ts_sync_mode**: How strictly to sync streams based on secondary input timestamps:
    *   `default`: Frame from secondary input with the nearest lower or equal timestamp to the primary input frame.
    *   `nearest`: Frame from secondary input with the absolute nearest timestamp to the primary input frame.

<span id="Audio-Filters"></span>
## 8 Audio Filters

Below is a description of the currently available audio filters.

### 8.1 aap
Apply Affine Projection algorithm to the first audio stream using the second audio stream.

*   **order**: Set the filter order.
*   **projection**: Set the projection order.
*   **mu**: Set the filter mu.
*   **delta**: Set the coefficient to initialize internal covariance matrix.
*   **out_mode**: Set the filter output samples.
    *   `i`: Pass the 1st input.
    *   `d`: Pass the 2nd input.
    *   `o`: Pass difference between desired, 2nd input and error signal estimate.
    *   `n`: Pass difference between input, 1st input and error signal estimate.
    *   `e`: Pass error signal estimated samples.
*   **precision**: Set which precision to use: `auto`, `float`, `double`.

### 8.2 acompressor
A compressor is mainly used to reduce the dynamic range of a signal.

*   **level_in**: Set input gain. Default is 1.
*   **mode**: `upward` or `downward`. Default is `downward`.
*   **threshold**: Volume level threshold. Default is 0.125.
*   **ratio**: Ratio by which the signal is reduced. Default is 2.
*   **attack**: Milliseconds before reduction starts. Default is 20.
*   **release**: Milliseconds before reduction is decreased. Default is 250.
*   **makeup**: Amount signal is amplified after processing. Default is 1.
*   **knee**: Curve the sharp knee around the threshold. Default is 2.82843.
*   **link**: `average` or `maximum` channel level affects reduction.
*   **detection**: `peak` or `rms`. Default is `rms`.
*   **mix**: How much to use compressed signal in output. Default is 1.

### 8.3 acontrast
Simple audio dynamic range compression/expansion filter.
*   **contrast**: Set contrast. Default is 33. Range [0, 100].

### 8.4 acopy
Copy the input audio source unchanged to the output.

### 8.5 acrossfade
Apply cross fade from one input audio stream to another.

*   **inputs, n**: Number of inputs to crossfade. Default is 2.
*   **nb_samples, ns**: Number of samples for cross fade. Default is 44100.
*   **duration, d**: Duration of cross fade effect.
*   **overlap, o**: Should first stream end overlap with second stream start. Default enabled.
*   **curve1, curve2**: Set curve for transition (e.g., `tri`, `qsin`, `exp`, etc.).

### 8.6 acrossover
Split audio stream into several bands.

*   **split**: Set split frequencies (positive and increasing).
*   **order**: Filter order (`2nd`, `4th`, ..., `20th`). Default is `4th`.
*   **level**: Input gain level. Default 1.
*   **gains**: Output gain for each band. Default 1.
*   **precision**: `auto`, `float`, `double`.

### 8.7 acrusher
Reduce audio bit resolution (bit crusher).

*   **level_in / level_out**: Input/output levels.
*   **bits**: Bit reduction.
*   **mix**: Mixing amount.
*   **mode**: `lin` (linear) or `log` (logarithmic).
*   **dc**: DC offset.
*   **aa**: Anti-aliasing.
*   **samples**: Sample reduction.
*   **lfo**: Enable LFO.

### 8.8 acue
Delay audio filtering until a given wallclock timestamp.

### 8.9 adeclick
Remove impulsive noise from input audio.

### 8.10 adeclip
Remove clipped samples from input audio.

### 8.11 adecorrelate
Apply decorrelation to input audio stream.

### 8.12 adelay
Delay one or more audio channels.
*   **delays**: List of delays in ms (e.g., `1500|0|500`). Use 'S' for samples, 's' for seconds.
*   **all**: Use last set delay for all remaining channels.

### 8.13 adenorm
Remedy denormals in audio by adding extremely low-level noise.

### 8.14 aderivative, aintegral
Compute derivative/integral of audio stream.

### 8.15 adrc
Apply spectral dynamic range controller.
*   **transfer**: Expression for transfer function.
*   **attack / release**: Timing in ms.

### 8.16 adynamicequalizer
Apply dynamic equalization.

### 8.17 adynamicsmooth
Apply dynamic smoothing.

### 8.18 aecho
Apply echoing to the input audio.
*   **in_gain / out_gain**: Gain settings.
*   **delays / decays**: List of intervals and loudness.

### 8.19 aemphasis
Audio emphasis filter (LP/CD restoration).

### 8.20 aeval
Modify an audio signal according to specified expressions.
*   **exprs**: '|'-separated expressions for each channel.
*   **channel_layout, c**: Output layout.

### 8.21 aexciter
Produce high sound harmonics not present in the original signal.

### 8.22 afade
Apply fade-in/out effect.
*   **type, t**: `in` or `out`.
*   **start_sample / nb_samples**: Timing by samples.
*   **start_time / duration**: Timing by duration.
*   **curve**: Curve type (`tri`, `qsin`, `log`, `exp`, etc.).

### 8.23 afftdn
Denoise audio samples with FFT.

### 8.24 afftfilt
Apply arbitrary expressions to samples in frequency domain.

### 8.25 afir
Apply an arbitrary Finite Impulse Response filter.
*   **dry / wet**: Gain settings.
*   **irnorm**: Normalization of IR coefficients.
*   **maxir**: Max allowed IR duration in seconds.

### 8.26 aformat
Set output format constraints (sample formats, rates, layouts).

### 8.27 afreqshift
Apply frequency shift to input audio samples.

### 8.28 afwtdn
Reduce broadband noise using Wavelets.

### 8.29 agate
Audio gate to reduce lower parts of a signal (noise floor).

### 8.30 aiir
Apply an arbitrary Infinite Impulse Response filter.

### 8.31 alimiter
Lookahead limiter to prevent signal from rising over a threshold.

### 8.32 allpass
Apply a two-pole all-pass filter.

### 8.33 aloop
Loop audio samples.

### 8.34 amerge
Merge two or more audio streams into a single multi-channel stream.

### 8.35 amix
Mixes multiple audio inputs into a single output.
*   **inputs**: Number of inputs.
*   **duration**: `longest`, `shortest`, `first`.
*   **weights**: Sequence of numbers for each input.

### 8.36 amultiply
Multiply first audio stream with second audio stream.

### 8.37 anequalizer
High-order parametric multiband equalizer for each channel.

### 8.38 anlmdn
Reduce broadband noise using Non-Local Means algorithm.

### 8.39 anlmf, anlms
Apply Normalized Least-Mean-(Squares|Fourth) algorithm.

### 8.40 anull
Pass the audio source unchanged.

### 8.41 apad
Pad the end of an audio stream with silence.

### 8.42 aphaser
Add a phasing effect.

### 8.43 aphaseshift
Apply phase shift to input audio.

### 8.44 apsnr
Measure Audio Peak Signal-to-Noise Ratio between two streams.

### 8.45 apsyclip
Apply Psychoacoustic clipper.

### 8.46 apulsator
Audio pulsator (between autopanner and tremolo).

### 8.47 aresample
Resample input audio using libswresample.

### 8.48 areverse
Reverse an audio clip.

### 8.49 arls
Apply Recursive Least Squares algorithm.

### 8.50 arnndn
Reduce noise from speech using Recurrent Neural Networks.

### 8.51 asdr
Measure Audio Signal-to-Distortion Ratio.

### 8.52 asetnsamples
Set the number of samples per each output audio frame.

### 8.53 asetrate
Set the sample rate without altering PCM data (changes speed/pitch).

### 8.54 ashowinfo
Show information for each input audio frame.

### 8.55 asisdr
Measure Audio Scaled-Invariant Signal-to-Distortion Ratio.

### 8.56 asoftclip
Apply audio soft clipping sigmoids.

### 8.57 aspectralstats
Display frequency domain statistical information.

### 8.58 asr
Automatic Speech Recognition using PocketSphinx.

### 8.59 astats
Display time domain statistical information (Bit depth, Peak, RMS, etc.).

### 8.60 asubboost
Boost subwoofer frequencies.

### 8.61 asubcut
Cut subwoofer frequencies (steeper than highpass).

### 8.62 asupercut
Cut super frequencies.

### 8.63 asuperpass
Apply high order Butterworth band-pass filter.

### 8.64 asuperstop
Apply high order Butterworth band-stop filter.

### 8.65 atempo
Adjust audio tempo without changing pitch. Range [0.5, 100.0].

### 8.66 atilt
Apply spectral tilt filter.

### 8.67 atrim
Trim audio to a continuous subpart.

### 8.68 axcorrelate
Calculate normalized windowed cross-correlation between two streams.

### 8.69 bandpass
Apply a two-pole Butterworth band-pass filter.

### 8.70 bandreject
Apply a two-pole Butterworth band-reject filter.

### 8.71 bass, lowshelf
Boost or cut bass frequencies using a shelving filter.

### 8.72 biquad
Apply a biquad IIR filter with given coefficients.

### 8.73 bs2b
Bauer stereo to binaural transformation for headphones.

### 8.74 channelmap
Remap input channels to new locations.

### 8.75 channelsplit
Split each channel into a separate output stream.

### 8.76 chorus
Add a chorus effect.

### 8.77 compand
Compress or expand audio's dynamic range.

### 8.78 compensationdelay
Metric-based delay to compensate for microphone/speaker positions.

### 8.79 crossfeed
Apply headphone crossfeed filter.

### 8.80 crystalizer
Algorithm for audio noise sharpening.

### 8.81 dcshift
Apply a DC shift to remove offsets.

### 8.82 deesser
Apply de-essing to audio samples.

### 8.83 dialoguenhance
Enhance dialogue in stereo audio (outputs 3.0).

### 8.84 drmeter
Measure audio dynamic range.

### 8.85 dynaudnorm
Dynamic Audio Normalizer.

### 8.86 earwax
Make audio easier to listen to on headphones (SoX port).

### 8.87 equalizer
Apply a two-pole peaking equalization filter.

### 8.88 extrastereo
Linearly increase difference between L/R channels for "live" effect.

### 8.89 firequalizer
Apply FIR Equalization using arbitrary frequency response.

### 8.90 flanger
Apply a flanging effect.

### 8.91 haas
Apply Haas effect to mono signals for stereo stretching.

### 8.92 hdcd
Decodes High Definition Compatible Digital (HDCD) data.

### 8.93 headphone
Apply HRTFs for virtual loudspeakers via headphones.

### 8.94 highpass
Apply a high-pass filter.

### 8.95 join
Join multiple input streams into one multi-channel stream.

### 8.96 ladspa
Load a LADSPA plugin.

### 8.97 loudnorm
EBU R128 loudness normalization.

### 8.98 lowpass
Apply a low-pass filter.

### 8.99 lv2
Load an LV2 plugin.

### 8.100 mcompand
Multiband compress or expand dynamic range.

### 8.101 pan
Mix channels with specific gain levels or remap channels.

### 8.102 replaygain
ReplayGain scanner filter.

### 8.103 resample
Internal filter for format/rate conversion.

### 8.104 rubberband
Time-stretching and pitch-shifting using librubberband.

### 120 volume
Adjust input audio volume.
*   **volume**: Expression or value (e.g., `0.5`, `6dB`).
*   **precision**: `fixed`, `float`, `double`.

---

<span id="Audio-Sources"></span>
## 9 Audio Sources

### 9.1 abuffer
Buffer audio frames for programmatic use.

### 9.2 aevalsrc
Generate an audio signal specified by an expression.
*   `aevalsrc="sin(440*2*PI*t):s=8000"`

### 9.6 anullsrc
Null audio source (silence).

### 9.8 anoisesrc
Generate noise (white, pink, brown, blue, violet, velvet).

### 9.11 sine
Generate a sine wave.

---

<span id="Video-Filters"></span>
## 11 Video Filters

### 11.1 addroi
Mark a region of interest (ROI) in a video frame.

### 11.14 blend, tblend
Blend two video frames (or consecutive frames) into each other.
*   **mode**: `addition`, `average`, `burn`, `darken`, `difference`, `multiply`, `screen`, etc.

### 11.18 boxblur
Apply a boxblur algorithm.

### 11.19 bwdif
Bob Weaver Deinterlacing Filter.

### 11.23 chromakey
YUV colorspace color/chroma keying.

### 11.34 colorkey
RGB colorspace color keying.

### 11.39 colorspace
Convert colorspace, transfer characteristics, or color primaries.

### 11.41 convolution
Apply convolution matrix (3x3, 5x5, 7x7).

### 11.47 crop
Crop the input video.
*   `crop=100:100:12:34`

### 11.72 drawbox
Draw a colored box on the video.

### 11.75 drawtext
Draw text on top of video using libfreetype.
*   `drawtext="text='Test Text':x=100:y=50:fontsize=24:fontcolor=yellow"`

### 11.81 eq
Adjust brightness, contrast, saturation, and gamma.

### 11.86 fade
Apply a fade-in/out effect.

### 11.97 format
Convert input video to specific pixel formats.

### 11.98 fps
Convert video to specified constant frame rate.

### 11.107 gblur
Apply Gaussian blur.

### 11.124 hstack / 11.277 vstack
Stack input videos horizontally or vertically.

### 11.143 libplacebo
Flexible GPU-accelerated processing (scaling, tone mapping, debanding).

### 11.182 overlay
Overlay one video on top of another.

### 11.184 pad
Add paddings to the input image.

### 11.215 scale
Scale (resize) the input video using libswscale.

### 11.258 transpose
Transpose rows with columns (rotate 90 degrees).

### 11.287 yadif
Yet Another Deinterlacing Filter.

---

<span id="CUDA-Video-Filters"></span>
## 12 CUDA Video Filters

Nvidia CUDA accelerated filters. Requires Nvidia CUDA Toolkit.

*   **bilateral_cuda**: Edge preserving spatial smoothing.
*   **chromakey_cuda**: CUDA accelerated chroma keying.
*   **overlay_cuda**: CUDA accelerated overlay.
*   **scale_cuda**: CUDA accelerated scaling and format conversion.
*   **yadif_cuda**: CUDA accelerated deinterlacing.

---

<span id="OpenCL-Video-Filters"></span>
## 13 OpenCL Video Filters

GPU accelerated filters using OpenCL.

*   **avgblur_opencl**: Average blur.
*   **boxblur_opencl**: Box blur.
*   **tonemap_opencl**: HDR to SDR conversion.
*   **unsharp_opencl**: Sharpen or blur.

---

<span id="VAAPI-Video-Filters"></span>
## 14 VAAPI Video Filters

Hardware accelerated filters for Intel/AMD via VA-API.

*   **overlay_vaapi**: Hardware overlay.
*   **tonemap_vaapi**: HDR tone mapping.
*   **xstack_vaapi**: Hardware accelerated stacking.

---

<span id="Video-Sources"></span>
## 18 Video Sources

### 18.7 mandelbrot
Generate a Mandelbrot set fractal.

### 18.10 life
Generate a Conway's Game of Life pattern.

### 18.13 testsrc, color, nullsrc
*   **testsrc**: Generate a test pattern.
*   **color**: Generate a solid color.
*   **nullsrc**: Generate empty frames.

---

<span id="Multimedia-Filters"></span>
## 20 Multimedia Filters

### 20.10 ebur128
EBU R128 loudness analysis.

### 20.26 showspectrum
Convert audio to a frequency spectrum video.

### 20.29 showwaves
Convert audio to a sample waves video.

### 20.33 split, asplit
Split input into several identical outputs.